{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fair and Robust Sample Selection on the Synthetic Dataset\n",
    "## With Label Flipping\n",
    "\n",
    "#### This Jupyter Notebook simulates the proposed fair and robust sample selection on the synthetic data.\n",
    "#### We use two fairness metrics: equalized odds and demographic parity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import copy\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import Sampler\n",
    "import torch\n",
    "\n",
    "from models import LogisticRegression, weights_init_normal, test_model\n",
    "from FairRobustSampler import FairRobust, CustomDataset\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process the data\n",
    "In the synthetic_data directory, there are a total of 11 numpy files including training data (both clean and noisy), validation data, and test data. Note that the validation data is utilized for another method in the paper (i.e., FR-Train), so the data is not used in this program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xz_train = np.load('./synthetic_data/xz_train.npy')\n",
    "y_train = np.load('./synthetic_data/y_train.npy')\n",
    "z_train = np.load('./synthetic_data/z_train.npy')\n",
    "\n",
    "y_noise = np.load('./synthetic_data/y_noise_general.npy') # Labels with the general label flipping (details are in the paper)\n",
    "poi_ratio = 0.1\n",
    "\n",
    "xz_test = np.load('./synthetic_data/xz_test.npy')\n",
    "y_test = np.load('./synthetic_data/y_test.npy') \n",
    "z_test = np.load('./synthetic_data/z_test.npy')\n",
    "\n",
    "xz_train = torch.FloatTensor(xz_train)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "z_train = torch.FloatTensor(z_train)\n",
    "\n",
    "y_noise = torch.FloatTensor(y_noise)\n",
    "\n",
    "xz_test = torch.FloatTensor(xz_test)\n",
    "y_test = torch.FloatTensor(y_test)\n",
    "z_test = torch.FloatTensor(z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    xz_train = xz_train.cuda()\n",
    "    y_noise = y_noise.cuda()\n",
    "    y_train = y_train.cuda()\n",
    "    z_train = z_train.cuda()\n",
    "    \n",
    "    xz_test = xz_test.cuda()\n",
    "    y_test = y_test.cuda()\n",
    "    z_test = z_test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Number of Data ----------\n",
      "Train data : 2000, Test data : 1000 \n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"---------- Number of Data ----------\" )\n",
    "print(\n",
    "    \"Train data : %d, Test data : %d \"\n",
    "    % (len(y_train), len(y_test))\n",
    ")       \n",
    "print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model, train_features, labels, optimizer, criterion):\n",
    "    \"\"\"Trains the model with the given train data.\n",
    "\n",
    "    Args:\n",
    "        model: A torch model to train.\n",
    "        train_features: A torch tensor indicating the train features.\n",
    "        labels: A torch tensor indicating the true labels.\n",
    "        optimizer: A torch optimizer.\n",
    "        criterion: A torch criterion.\n",
    "\n",
    "    Returns:\n",
    "        loss values.\n",
    "    \"\"\"\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    label_predicted = model.forward(train_features)\n",
    "    loss  = criterion((F.tanh(label_predicted.squeeze())+1)/2, (labels.squeeze()+1)/2)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Fair and Robust Sample Selection w.r.t. Equalized Odds\n",
    "### The results are in the Experiments section of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Seed: 0 >\n",
      "  Test accuracy: 0.7270000576972961, EO disparity: 0.07098265895953759\n",
      "----------------------------------------------------------------------\n",
      "< Seed: 1 >\n",
      "  Test accuracy: 0.7240000367164612, EO disparity: 0.050096339113680166\n",
      "----------------------------------------------------------------------\n",
      "< Seed: 2 >\n",
      "  Test accuracy: 0.7220000624656677, EO disparity: 0.059576107899807385\n",
      "----------------------------------------------------------------------\n",
      "< Seed: 3 >\n",
      "  Test accuracy: 0.7310000061988831, EO disparity: 0.07098265895953759\n",
      "----------------------------------------------------------------------\n",
      "< Seed: 4 >\n",
      "  Test accuracy: 0.7300000190734863, EO disparity: 0.06905587668593449\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "full_tests = []\n",
    "\n",
    "parameters = Namespace(warm_start=100, tau=1-poi_ratio, alpha = 0.001, batch_size = 100)\n",
    "\n",
    "# Set the train data\n",
    "train_data = CustomDataset(xz_train, y_noise, z_train)\n",
    "\n",
    "seeds = [0,1,2,3,4]\n",
    "\n",
    "for seed in seeds:\n",
    "    \n",
    "    print(\"< Seed: {} >\".format(seed))\n",
    "    \n",
    "    # ---------------------\n",
    "    #  Initialize model, optimizer, and criterion\n",
    "    # ---------------------\n",
    "    \n",
    "    model = LogisticRegression(3,1).cuda()\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    model.apply(weights_init_normal)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, betas=(0.9, 0.999))\n",
    "    criterion = torch.nn.BCELoss()\n",
    "\n",
    "    losses = []\n",
    "    \n",
    "    # ---------------------\n",
    "    #  Define FairRobust and DataLoader\n",
    "    # ---------------------\n",
    "\n",
    "    sampler = FairRobust (model, train_data.x, train_data.y, train_data.z, target_fairness = 'eqodds', parameters = parameters, replacement = False, seed = seed)\n",
    "    train_loader = torch.utils.data.DataLoader (train_data, sampler=sampler, num_workers=0)\n",
    "\n",
    "    # ---------------------\n",
    "    #  Model training\n",
    "    # ---------------------\n",
    "    for epoch in range(400):\n",
    "        print(epoch, end=\"\\r\")\n",
    "        \n",
    "        tmp_loss = []\n",
    "        \n",
    "        for batch_idx, (data, target, z) in enumerate (train_loader):\n",
    "            loss = run_epoch (model, data, target, optimizer, criterion)\n",
    "            tmp_loss.append(loss)\n",
    "            \n",
    "        losses.append(sum(tmp_loss)/len(tmp_loss))\n",
    "        \n",
    "    tmp_test = test_model(model, xz_test, y_test, z_test)\n",
    "    full_tests.append(tmp_test)\n",
    "    \n",
    "    print(\"  Test accuracy: {}, EO disparity: {}\".format(tmp_test['Acc'], tmp_test['EqOdds_diff']))\n",
    "    print(\"----------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy (avg): 0.7268000364303588\n",
      "EO disparity  (avg): 0.06413872832369945\n"
     ]
    }
   ],
   "source": [
    "tmp_acc = []\n",
    "tmp_eo = []\n",
    "for i in range(len(seeds)):\n",
    "    tmp_acc.append(full_tests[i]['Acc'])\n",
    "    tmp_eo.append(full_tests[i]['EqOdds_diff'])\n",
    "\n",
    "print(\"Test accuracy (avg): {}\".format(sum(tmp_acc)/len(tmp_acc)))\n",
    "print(\"EO disparity  (avg): {}\".format(sum(tmp_eo)/len(tmp_eo)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fair and Robust Sample Selection w.r.t. Demographic Parity\n",
    "### The results are in the Experiments section of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Seed: 0 >\n",
      "  Test accuracy: 0.7190000414848328, DP disparity: 0.005151515151515129\n",
      "----------------------------------------------------------------------\n",
      "< Seed: 1 >\n",
      "  Test accuracy: 0.7200000286102295, DP disparity: 0.00615151515151513\n",
      "----------------------------------------------------------------------\n",
      "< Seed: 2 >\n",
      "  Test accuracy: 0.7210000157356262, DP disparity: 0.00410101010101005\n",
      "----------------------------------------------------------------------\n",
      "< Seed: 3 >\n",
      "  Test accuracy: 0.7200000286102295, DP disparity: 0.00615151515151513\n",
      "----------------------------------------------------------------------\n",
      "< Seed: 4 >\n",
      "  Test accuracy: 0.718000054359436, DP disparity: 0.0072020202020202095\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "full_tests = []\n",
    "\n",
    "parameters = Namespace(warm_start=100, tau=1-poi_ratio, alpha = 0.001, batch_size = 100)\n",
    "\n",
    "# Set the train data\n",
    "train_data = CustomDataset(xz_train, y_noise, z_train)\n",
    "\n",
    "seeds = [0,1,2,3,4]\n",
    "\n",
    "for seed in seeds:\n",
    "    \n",
    "    print(\"< Seed: {} >\".format(seed))\n",
    "    \n",
    "    # ---------------------\n",
    "    #  Initialize model, optimizer, and criterion\n",
    "    # ---------------------\n",
    "    \n",
    "    model = LogisticRegression(3,1).cuda()\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    model.apply(weights_init_normal)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, betas=(0.9, 0.999))\n",
    "    criterion = torch.nn.BCELoss()\n",
    "\n",
    "    losses = []\n",
    "    \n",
    "    # ---------------------\n",
    "    #  Define FairRobust and DataLoader\n",
    "    # ---------------------\n",
    "\n",
    "    sampler = FairRobust (model, train_data.x, train_data.y, train_data.z, target_fairness = 'dp', parameters = parameters, replacement = False, seed = seed)\n",
    "    train_loader = torch.utils.data.DataLoader (train_data, sampler=sampler, num_workers=0)\n",
    "\n",
    "    # ---------------------\n",
    "    #  Model training\n",
    "    # ---------------------\n",
    "    for epoch in range(400):\n",
    "        print(epoch, end=\"\\r\")\n",
    "        \n",
    "        tmp_loss = []\n",
    "        \n",
    "        for batch_idx, (data, target, z) in enumerate (train_loader):\n",
    "            loss = run_epoch (model, data, target, optimizer, criterion)\n",
    "            tmp_loss.append(loss)\n",
    "            \n",
    "        losses.append(sum(tmp_loss)/len(tmp_loss))\n",
    "        \n",
    "    tmp_test = test_model(model, xz_test, y_test, z_test)\n",
    "    full_tests.append(tmp_test)\n",
    "    \n",
    "    print(\"  Test accuracy: {}, DP disparity: {}\".format(tmp_test['Acc'], tmp_test['DP_diff']))\n",
    "    print(\"----------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy (avg): 0.7196000337600708\n",
      "DP disparity  (avg): 0.00575151515151513\n"
     ]
    }
   ],
   "source": [
    "tmp_acc = []\n",
    "tmp_dp = []\n",
    "for i in range(len(seeds)):\n",
    "    tmp_acc.append(full_tests[i]['Acc'])\n",
    "    tmp_dp.append(full_tests[i]['DP_diff'])\n",
    "\n",
    "print(\"Test accuracy (avg): {}\".format(sum(tmp_acc)/len(tmp_acc)))\n",
    "print(\"DP disparity  (avg): {}\".format(sum(tmp_dp)/len(tmp_dp)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
